None
https://app.neptune.ai/dev.newjacob19/Adversarial-segmentation/e/AD-52
Neptune is On-line
Torch version: 1.11, 1.11.0+cu102
Using regular batch norm
dataset = cityscapes
ignore_label = 255
num_classes = 19
cv split val 0 ['val/munster', 'val/lindau', 'val/frankfurt']
mode val found 500 images
cn num_classes 19
cv split train 0 ['train/aachen', 'train/bochum', 'train/bremen', 'train/cologne', 'train/darmstadt', 'train/dusseldorf', 'train/erfurt', 'train/hamburg', 'train/hanover', 'train/jena', 'train/krefeld', 'train/monchengladbach', 'train/strasbourg', 'train/stuttgart', 'train/tubingen', 'train/ulm', 'train/weimar', 'train/zurich']
mode train found 2975 images
cn num_classes 19
Loading centroid file /SSD1/jisu/deeplabv3/uniform_centroids/cityscapes_cv0_tile1024.json
Found 19 centroids
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
Using Cross Entropy Loss
Using Cross Entropy Loss
Trunk: resnet-50
Model params = 40.4M
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
[epoch 0], [iter 1 / 1487], [train stage1 loss 3.830265 (Seg loss 3.1378419399261475, Adv loss 0.6924231648445129)], [Stage1 lr 0.005000]
[train stage2 loss 0.693464 (real loss 0.7184251546859741, fake loss 0.6685030460357666)], [Stage2 lr 0.090000] [batchtime 0]
[epoch 0], [iter 2 / 1487], [train stage1 loss 3.410798 (Seg loss 2.99133038520813, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 25.346732 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 0]
[epoch 0], [iter 3 / 1487], [train stage1 loss 3.099287 (Seg loss 2.4762661457061768, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 33.564488 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 0]
[epoch 0], [iter 4 / 1487], [train stage1 loss 2.986402 (Seg loss 2.647747755050659, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 37.673366 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 0]
[epoch 0], [iter 5 / 1487], [train stage1 loss 2.769831 (Seg loss 1.9035433530807495, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 40.138693 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 0]
[epoch 0], [iter 6 / 1487], [train stage1 loss 2.570782 (Seg loss 1.5755410194396973, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 41.782244 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 0]
[epoch 0], [iter 7 / 1487], [train stage1 loss 2.390803 (Seg loss 1.3109264373779297, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 42.956209 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 0]
[epoch 0], [iter 8 / 1487], [train stage1 loss 2.252147 (Seg loss 1.2815555334091187, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 43.836683 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 0]
[epoch 0], [iter 9 / 1487], [train stage1 loss 2.163266 (Seg loss 1.4522216320037842, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 44.521496 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 0]
[epoch 0], [iter 10 / 1487], [train stage1 loss 2.107813 (Seg loss 1.608731985092163, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 45.069346 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 0]
[epoch 0], [iter 11 / 1487], [train stage1 loss 2.130863 (Seg loss 2.3613672256469727, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 45.517588 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 0.976]
[epoch 0], [iter 12 / 1487], [train stage1 loss 2.102323 (Seg loss 1.788381814956665, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 45.891122 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 0.992]
[epoch 0], [iter 13 / 1487], [train stage1 loss 2.027651 (Seg loss 1.1315897703170776, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 46.207190 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1]
[epoch 0], [iter 14 / 1487], [train stage1 loss 2.075443 (Seg loss 2.696737051010132, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 46.478105 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1]
[epoch 0], [iter 15 / 1487], [train stage1 loss 2.024625 (Seg loss 1.3131755590438843, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 46.712898 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1]
[epoch 0], [iter 16 / 1487], [train stage1 loss 1.957852 (Seg loss 0.9562591910362244, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 46.918342 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1]
[epoch 0], [iter 17 / 1487], [train stage1 loss 1.902958 (Seg loss 1.024647831916809, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 47.099616 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 18 / 1487], [train stage1 loss 1.944147 (Seg loss 2.644364833831787, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 47.260748 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 19 / 1487], [train stage1 loss 1.935642 (Seg loss 1.782543420791626, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 47.404919 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 20 / 1487], [train stage1 loss 1.878023 (Seg loss 0.7832685112953186, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 47.534673 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 21 / 1487], [train stage1 loss 1.838958 (Seg loss 1.0576575994491577, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 47.652070 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 22 / 1487], [train stage1 loss 1.787556 (Seg loss 0.7081087231636047, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 47.758794 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 23 / 1487], [train stage1 loss 1.748215 (Seg loss 0.8827059864997864, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 47.856238 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 24 / 1487], [train stage1 loss 1.755096 (Seg loss 1.913377046585083, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 47.945561 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 25 / 1487], [train stage1 loss 1.755891 (Seg loss 1.7749595642089844, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.027739 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 26 / 1487], [train stage1 loss 1.709693 (Seg loss 0.5547506213188171, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.103595 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 27 / 1487], [train stage1 loss 1.680775 (Seg loss 0.9288979172706604, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.173832 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 28 / 1487], [train stage1 loss 1.700152 (Seg loss 2.223330497741699, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.239052 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 29 / 1487], [train stage1 loss 1.702250 (Seg loss 1.7609909772872925, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.299775 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 30 / 1487], [train stage1 loss 1.678105 (Seg loss 0.9779115319252014, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.356449 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 31 / 1487], [train stage1 loss 1.663081 (Seg loss 1.2123472690582275, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.409467 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 32 / 1487], [train stage1 loss 1.639853 (Seg loss 0.9197788238525391, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.459171 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 33 / 1487], [train stage1 loss 1.617424 (Seg loss 0.8997255563735962, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.505863 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 34 / 1487], [train stage1 loss 1.613948 (Seg loss 1.4992165565490723, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.549808 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 35 / 1487], [train stage1 loss 1.594598 (Seg loss 0.9367109537124634, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.591242 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 36 / 1487], [train stage1 loss 1.611446 (Seg loss 2.201112985610962, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.630374 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 37 / 1487], [train stage1 loss 1.613449 (Seg loss 1.6855719089508057, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.667391 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 38 / 1487], [train stage1 loss 1.620717 (Seg loss 1.8896151781082153, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.702460 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 39 / 1487], [train stage1 loss 1.604580 (Seg loss 0.9914005994796753, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.735730 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 40 / 1487], [train stage1 loss 1.592046 (Seg loss 1.1031920909881592, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.767337 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 41 / 1487], [train stage1 loss 1.570122 (Seg loss 0.6931890845298767, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.797402 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 42 / 1487], [train stage1 loss 1.566367 (Seg loss 1.412381887435913, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.826035 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 43 / 1487], [train stage1 loss 1.570093 (Seg loss 1.7265969514846802, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.853336 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 44 / 1487], [train stage1 loss 1.557836 (Seg loss 1.0308080911636353, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.879397 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 45 / 1487], [train stage1 loss 1.536261 (Seg loss 0.5869266390800476, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.904299 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 46 / 1487], [train stage1 loss 1.517920 (Seg loss 0.6926025748252869, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.928119 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 47 / 1487], [train stage1 loss 1.492472 (Seg loss 0.32183921337127686, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.950925 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 48 / 1487], [train stage1 loss 1.487634 (Seg loss 1.2602462768554688, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.972781 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 49 / 1487], [train stage1 loss 1.500508 (Seg loss 2.118464469909668, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 48.993744 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 50 / 1487], [train stage1 loss 1.520339 (Seg loss 2.4920499324798584, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.013869 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 51 / 1487], [train stage1 loss 1.513438 (Seg loss 1.1683887243270874, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.033205 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 52 / 1487], [train stage1 loss 1.499591 (Seg loss 0.7934249639511108, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.051797 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 53 / 1487], [train stage1 loss 1.507385 (Seg loss 1.9126839637756348, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.069688 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 54 / 1487], [train stage1 loss 1.500607 (Seg loss 1.1413249969482422, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.086916 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 55 / 1487], [train stage1 loss 1.498037 (Seg loss 1.3592859506607056, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.103518 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 56 / 1487], [train stage1 loss 1.480995 (Seg loss 0.5436583161354065, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.119526 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 57 / 1487], [train stage1 loss 1.498124 (Seg loss 2.4573974609375, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.134973 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 58 / 1487], [train stage1 loss 1.490708 (Seg loss 1.0679551362991333, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.149887 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 59 / 1487], [train stage1 loss 1.485695 (Seg loss 1.1949256658554077, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.164296 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 60 / 1487], [train stage1 loss 1.485252 (Seg loss 1.4591385126113892, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.178224 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 61 / 1487], [train stage1 loss 1.471226 (Seg loss 0.6296657919883728, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.191696 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 62 / 1487], [train stage1 loss 1.461441 (Seg loss 0.8645390272140503, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.204733 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 63 / 1487], [train stage1 loss 1.456281 (Seg loss 1.1364129781723022, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.217357 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 64 / 1487], [train stage1 loss 1.447681 (Seg loss 0.9058464169502258, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.229585 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 65 / 1487], [train stage1 loss 1.454227 (Seg loss 1.8731478452682495, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.241438 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 66 / 1487], [train stage1 loss 1.446910 (Seg loss 0.9713354110717773, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.252931 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 67 / 1487], [train stage1 loss 1.459380 (Seg loss 2.2824015617370605, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.264082 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 68 / 1487], [train stage1 loss 1.449941 (Seg loss 0.8174923658370972, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.274904 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 69 / 1487], [train stage1 loss 1.446986 (Seg loss 1.2460823059082031, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.285413 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 70 / 1487], [train stage1 loss 1.438708 (Seg loss 0.8675426244735718, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.295621 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 71 / 1487], [train stage1 loss 1.436031 (Seg loss 1.2486355304718018, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.305542 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 72 / 1487], [train stage1 loss 1.432671 (Seg loss 1.194121241569519, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.315187 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 73 / 1487], [train stage1 loss 1.421852 (Seg loss 0.6428651809692383, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.324568 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 74 / 1487], [train stage1 loss 1.423596 (Seg loss 1.550890564918518, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.333695 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 75 / 1487], [train stage1 loss 1.415277 (Seg loss 0.7996463179588318, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.342580 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 76 / 1487], [train stage1 loss 1.410588 (Seg loss 1.058925986289978, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.351230 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 77 / 1487], [train stage1 loss 1.405873 (Seg loss 1.0475294589996338, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.359655 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 78 / 1487], [train stage1 loss 1.397173 (Seg loss 0.7273099422454834, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.367865 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 79 / 1487], [train stage1 loss 1.388782 (Seg loss 0.7342991828918457, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.375867 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 80 / 1487], [train stage1 loss 1.379374 (Seg loss 0.6361372470855713, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.383668 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 81 / 1487], [train stage1 loss 1.402289 (Seg loss 3.2354414463043213, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.391277 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 82 / 1487], [train stage1 loss 1.409401 (Seg loss 1.985501766204834, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.398701 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 83 / 1487], [train stage1 loss 1.399469 (Seg loss 0.5850623250007629, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.405945 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 84 / 1487], [train stage1 loss 1.394733 (Seg loss 1.0015878677368164, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.413017 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 85 / 1487], [train stage1 loss 1.387831 (Seg loss 0.8080617189407349, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.419923 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 86 / 1487], [train stage1 loss 1.383575 (Seg loss 1.021828293800354, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.426668 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 87 / 1487], [train stage1 loss 1.378489 (Seg loss 0.9411433935165405, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.433258 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 88 / 1487], [train stage1 loss 1.390992 (Seg loss 2.4786882400512695, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.439698 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 89 / 1487], [train stage1 loss 1.386547 (Seg loss 0.9953939914703369, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.445994 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 90 / 1487], [train stage1 loss 1.407498 (Seg loss 3.2721316814422607, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.452150 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 91 / 1487], [train stage1 loss 1.413820 (Seg loss 1.982856035232544, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.458170 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 92 / 1487], [train stage1 loss 1.407496 (Seg loss 0.8320125937461853, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.464059 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 93 / 1487], [train stage1 loss 1.413175 (Seg loss 1.9355992078781128, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.469822 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 94 / 1487], [train stage1 loss 1.407810 (Seg loss 0.9088963866233826, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.475462 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 95 / 1487], [train stage1 loss 1.404348 (Seg loss 1.0788743495941162, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.480984 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 96 / 1487], [train stage1 loss 1.405198 (Seg loss 1.485992431640625, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.486390 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 97 / 1487], [train stage1 loss 1.406202 (Seg loss 1.5025336742401123, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.491685 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 98 / 1487], [train stage1 loss 1.403198 (Seg loss 1.1118921041488647, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.496872 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 99 / 1487], [train stage1 loss 1.396488 (Seg loss 0.7388882040977478, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.501954 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 100 / 1487], [train stage1 loss 1.391030 (Seg loss 0.8506773114204407, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.506935 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 101 / 1487], [train stage1 loss 1.394485 (Seg loss 1.7400107383728027, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.511816 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 102 / 1487], [train stage1 loss 1.414236 (Seg loss 3.4090468883514404, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.516603 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 103 / 1487], [train stage1 loss 1.410774 (Seg loss 1.0576430559158325, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.521296 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 104 / 1487], [train stage1 loss 1.409166 (Seg loss 1.243533730506897, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.525899 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 105 / 1487], [train stage1 loss 1.403267 (Seg loss 0.7898072004318237, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.530414 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 106 / 1487], [train stage1 loss 1.400731 (Seg loss 1.1344562768936157, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.534844 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 107 / 1487], [train stage1 loss 1.396268 (Seg loss 0.9231669306755066, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.539191 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 108 / 1487], [train stage1 loss 1.389711 (Seg loss 0.6881486177444458, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.543458 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 109 / 1487], [train stage1 loss 1.389545 (Seg loss 1.3716256618499756, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.547646 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 110 / 1487], [train stage1 loss 1.389782 (Seg loss 1.415549635887146, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.551759 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 111 / 1487], [train stage1 loss 1.385892 (Seg loss 0.9580579996109009, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.555797 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 112 / 1487], [train stage1 loss 1.380924 (Seg loss 0.8294553160667419, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.559763 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 113 / 1487], [train stage1 loss 1.375136 (Seg loss 0.7268149852752686, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.563659 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 114 / 1487], [train stage1 loss 1.371320 (Seg loss 0.9401950240135193, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.567487 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 115 / 1487], [train stage1 loss 1.376386 (Seg loss 1.9538302421569824, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.571248 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 116 / 1487], [train stage1 loss 1.372836 (Seg loss 0.9646819233894348, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.574944 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 117 / 1487], [train stage1 loss 1.368350 (Seg loss 0.8479514122009277, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.578577 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 118 / 1487], [train stage1 loss 1.363962 (Seg loss 0.8505021333694458, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.582148 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 119 / 1487], [train stage1 loss 1.358015 (Seg loss 0.6563262343406677, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.585659 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 120 / 1487], [train stage1 loss 1.354875 (Seg loss 0.9811490178108215, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.589112 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 121 / 1487], [train stage1 loss 1.353522 (Seg loss 1.191257119178772, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.592508 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 122 / 1487], [train stage1 loss 1.348467 (Seg loss 0.7367674708366394, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.595848 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 123 / 1487], [train stage1 loss 1.345796 (Seg loss 1.0199118852615356, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.599134 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 124 / 1487], [train stage1 loss 1.343607 (Seg loss 1.0743167400360107, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.602367 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 125 / 1487], [train stage1 loss 1.340973 (Seg loss 1.0143991708755493, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.605548 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 126 / 1487], [train stage1 loss 1.336111 (Seg loss 0.7284033298492432, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.608678 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 127 / 1487], [train stage1 loss 1.333691 (Seg loss 1.0287342071533203, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.611760 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 128 / 1487], [train stage1 loss 1.330385 (Seg loss 0.9105338454246521, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.614793 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 129 / 1487], [train stage1 loss 1.328878 (Seg loss 1.1359928846359253, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.617779 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 130 / 1487], [train stage1 loss 1.324381 (Seg loss 0.7443057894706726, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.620719 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 131 / 1487], [train stage1 loss 1.318830 (Seg loss 0.5971418619155884, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.623614 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 132 / 1487], [train stage1 loss 1.317591 (Seg loss 1.155332326889038, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.626466 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 133 / 1487], [train stage1 loss 1.313345 (Seg loss 0.7527951598167419, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.629274 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 134 / 1487], [train stage1 loss 1.318915 (Seg loss 2.0598254203796387, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.632041 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 135 / 1487], [train stage1 loss 1.317696 (Seg loss 1.1542927026748657, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.634766 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 136 / 1487], [train stage1 loss 1.317531 (Seg loss 1.2952992916107178, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.637452 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 137 / 1487], [train stage1 loss 1.312092 (Seg loss 0.572287380695343, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.640098 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 138 / 1487], [train stage1 loss 1.310474 (Seg loss 1.088811993598938, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.642706 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 139 / 1487], [train stage1 loss 1.305805 (Seg loss 0.6614781618118286, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.645277 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 140 / 1487], [train stage1 loss 1.303362 (Seg loss 0.9638712406158447, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.647810 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 141 / 1487], [train stage1 loss 1.299067 (Seg loss 0.6976931691169739, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.650308 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 142 / 1487], [train stage1 loss 1.294898 (Seg loss 0.7071335911750793, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.652771 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 143 / 1487], [train stage1 loss 1.290853 (Seg loss 0.7164608240127563, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.655199 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 144 / 1487], [train stage1 loss 1.291184 (Seg loss 1.3384408950805664, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.657594 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 145 / 1487], [train stage1 loss 1.288631 (Seg loss 0.9210527539253235, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.659955 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 146 / 1487], [train stage1 loss 1.285079 (Seg loss 0.7700605392456055, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.662284 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 147 / 1487], [train stage1 loss 1.280341 (Seg loss 0.5885863900184631, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.664581 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]
[epoch 0], [iter 148 / 1487], [train stage1 loss 1.275429 (Seg loss 0.5533638000488281, Adv loss 0.0)], [Stage1 lr 0.005000]
[train stage2 loss 49.666848 (real loss 0.0, fake loss 100.0)], [Stage2 lr 0.090000] [batchtime 1.01]